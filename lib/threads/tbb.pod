
=head1 NAME

threads::tbb - interface to the Threading Building Blocks (TBB) API

=head1 SYNOPSIS / TODO

 # first instance:
 #   - records %INC
 #   - adds to @INC a closure that keeps a track of loaded modules
 use threads::tbb;

 # this creates a tbb::task_scheduler_init (C++ name) object
 my $tbb = threads::tbb->new(
     threads => 4,  # optional, specify number of workers
     modules => [ ... ],  # optional, specify modules to load
 );

 # a chunked sequence generator
 my $range_i = threads::tbb::blocked_int->new(1, 40, 5);

 # a concurrent arrays: deep copy in and out
 tie my @data, "threads::tbb::concurrent::array";

 # do data parallel work
 $tbb->parallel_for($range_i, \&execute);

 # map/reduce
 my $result = parallel_reduce($range_i, \&execute, \&join);

=head1 DESCRIPTION

This module provides access to a few core TBB API functions to Perl
programs.

The algorithms employed by TBB are quite different to threads as
provided by L<use threads;> - instead of directly starting threads and
managing their activity and communication/synchronisation, an API is
provided that provides I<data parallelism>;

=over

=item *

I<divide and conquer> processing with I<task stealing> via the
L</parallel_for> and L</parallel_reduce> APIs

=item *

(coming soon) I<data flow> processing via the L</pipeline> API

=item *

(later, maybe) I<task-oriented> programming via the L</task> API

=back

With C<threads::tbb>, you don't write your algorithms from the
perspective of a thread and what the thread should do next.  Instead,
just as when writing "co-operative multi-threading" programs as with
L<Event> or L<POE>, the challenge is to break heavy work into small
but substantial, generally non-blocking chunks of work.  "Substantial"
is yet to be quantified; it's likely to be around the ballpark of
1,000's of Perl runloop iterations.

As your program runs, the API allows the TBB library to keep queues
(trees actually) of runnable tasks.  These are identified and kept in
thread-affinitive task lists.  Other threads can come along to and
"steal" work from these lists, to keep cores busy.

What this means is that it is relatively easy to make programs which
can make best use of processing power available on newer multi-core
CPUs.  For the greatest scalability you will also need to use an
arena-based memory allocator; a simple way to do this is by setting
C<LD_PRELOAD=libtbbmalloc_proxy.so.2>.  See
L<http://software.intel.com/en-us/articles/optimizing-without-breaking-a-sweat/>

=head2 Worker Interpreters

When the first C<threads::tbb::init> object is made, one worker thread
is created for each processor core or virtual core.  This is performed
by the TBB library before the Perl interpreter can C<use strict;>

Subsequent calls to it will not create new worker pthreads, instead
they will re-use the existing threads.

Each worker thread is for the most part, completely isolated from the
other threads - just like C<use threads>.  Unlike C<use threads>, the
C<perl_clone()> function is never used; that's the part that XS
modules hardly ever implement anyway.  Instead, each thread must load
all of the modules required to get it to do useful work on its own.
This is largely automatic, however there are some things you may need
to be aware of.

First of all, the first time you:

  use threads::tbb;

At compile time, the library takes a copy of the %INC global variable
(see L<perlvar/%INC>).  It also places a special callback onto the
@INC global (see L<perlfunc/require>) which records all of the modules
later loaded by code.  Finally, it performs a little test designed to
see what library paths in @INC were set up automatically.

It builds these into two lists which are passed to the worker threads
for driving thread initialization before any work is done.  They can
be specified manually (as in L<threads::lite>):

  my $tbb = threads::tbb->new(
      lib => \@INC,
      modules => [ qw(Math::BigRat) ],
  );

=over

=item C<lib>

This is an ordered list of paths to prepend to @INC of the worker
threads before any modules are loaded.  If any paths already exist on
@INC of the worker thread, they are not duplicated.

=item C<modules>

This is an ordered list of modules to 'require' in the worker thread.
The modules in this list are specified in module-form (eg
"Math::BigRat").  If you want to specify instead a list of
require-form (eg "Math/BigRat.pm"), this is also possible:

  my $tbb = threads::tbb->new( requires => [ "Math/BigRat.pm" ] );

As the list of modules are processed, if any module encountered is
already in the C<%INC> - for instance, if it was loaded as a
dependency of another module - then it is not re-loaded.

The default is to take the C<%INC> saved from the module load, and
sort it such that, eg C<Moose/Object.pm> sorts after C<Moose.pm>, and
then after that alphabetically.  After this sorted list, any modules
which were seen by C<require> or C<use> are added to the list in the
order they were included in the main program.

=back

Note if you add paths to the beginning of C<@INC> yourself, I<after>
C<use threads::tbb> but before C<threads::tbb-E<gt>new()>, then
C<threads::tbb> will not see them.

=head2 Shared Data

Worker threads do not share any data with the main process.

All functions are passed as serialized closures initially via
C<L<Storable>>.  The serialization preserves closures to
C<threads::tbb::concurrent::> series of thread-safe containers.  All
other closed over variables are cloned and will take independent value
in each worker thread.

C<threads::shared> could also work, but it should only be used for
legacy code as it is Perl's answer to Python's GIL.  This will
probably special support to work.

=head1 METHODS

These methods are all called on the tbb object.

=head2 parallel_for

C<parallel_for> can be used to process a set of data.  First you must
put your data into a concurrent container.  Then, you can declare a
range over the keys of that container (eg, a range of integers).
Finally, call C<parallel_for> and pass it the range and a closure
which can make reference to the concurrent container.

  use threads::tbb;
  tie my @array, "threads::tbb::concurrent::array";

  @array = @data;  # lazy deep copy

  my $tbb = threads::tbb->new;

  # get a range for that array.  up to 5 at a time.
  my $array_range = threads::tbb::blocked_int->new(0, $#array+1, 5);

  # now run parallel_for
  $tbb->parallel_for( $array_range, sub {
      my $range = shift;

      # code may be executed in a thread.
      # we now have exclusive use of
      #   @array[$range->begin .. $range->end-1]

      for my $i ($range->begin .. $range->end-1) {
          my $val = $array[$i];  # another lazy deep copy

          $val->frobnicate();  # change it somehow

          $array[$i] = $val;   # lazy deep copy back
      }
  } );

It's a good idea not to assume that the concurrent containers are deep
copying values passed through them; the only safe access is to assign
an item from the container, and to assign an item back to the
container.  These operations will do deep copies where required, and
pass references where the values came from the same interpreter.  You
can expect more discussion on this on L<threads::tbb::concurrent>

=head2 parallel_map

The calling convention of C<parallel_for> allows you to manually
specify the "grain size" - the iterations required to to useful work.
It also reduces time spent in function call overhead.  However, a
simpler API is also available:

  use threads::tbb;

  my $tbb = threads::tbb->new;

  my @output = $tbb->parallel_map(sub {
      my $val = shift;
      $val->frobnicate();
      return $val;
  }, @input);

This indicates use of the c<tbb::auto_partitioner()>, which presumably
times how long it takes to process the block for given input sizes,
and adjusts the size of the blocks accordingly.

=head2 parallel_reduce

Parallel_reduce is just C<parallel_for>, but with another function to
combine results from the array at the end.  It's not called
C<parallel_forreduce> due to a similarity with an obscure Pirate
Interjection.

  use threads::tbb;

  tie my @array, "threads::tbb::concurrent::array";
  @array = @data;  # lazy deep copy

  # get a range for that array.  up to 5 at a time.
  my $array_range = threads::tbb::blocked_int->new(0, $#array+1, 5);

  my $tbb = threads::tbb->new;

  # now run parallel_for
  my $answer = $tbb->parallel_reduce( $array_range, sub {
      my $range = shift;

      # code may be executed in a thread.
      # we now have exclusive use of
      #   @array[$range->begin .. $range->end-1]

      my $price = 0;
      for my $i ($range->begin .. $range->end-1) {
          my $val = $array[$i];  # another lazy deep copy

          $price += $val->compute_cost();
      }
      return $price;
  },
  sub {
      # fold a value from a and b to a new value.
      # lazy deep copies in and out.  Check b is not undef.
      my ($a, $b) = @_;
      return defined $b ? $a + $b : $a;
  },
  );

=head2 pipeline / filter #TODO

This extremely useful API allows you to structure code that performs
multiple discrete steps on a continuous stream of data, with worker
threads picking up whatever needs doing.

=head2 parallel_while #TODO

This one could potentially be used to implement a generic
multi-processor event loop.

  my $i = 20;
  my $iterator = sub {
      $i-- || undef;
  };
  # deep copied to the sub in this block
  parallel_while($iterator, sub {

      # you can add another iterator to the while block
      parallel_while_add($iterator2);

  });

Each of the iterators added run in the thread context of the
interpreter that added them.

=head2 parallel_sort #TODO

Sorting with some scalability.  No plan for this yet; it probably also
would not scale beyond one processor without naughty cross-thread
peeking (see L<threads::tbb::concurrent>)

=head2 parallel_scan #TODO #LATER

... an obscure one; see http://en.wikipedia.org/wiki/Prefix_sum ...

Not implemented.

=head1 SEE ALSO

L<threads>, L<threads::lite>

L<http://threadingbuildingblocks.org>

B<Intel Threading Building Blocks>: Outfitting C++ for Multi-core
Processor Parallelism, By James Reinders.  Publisher: O'Reilly Media.
Released: July 2007.  L<isbn://978-0-596-51480-8> (print)
L<isbn://978-0-596-15959-7> (ebook).

=head1 AUTHOR AND LICENSE

C<threads::tbb> was written by Sam Vilain L<sam.vilain@openparallel.com>

Copyright (c) 2011, OpenParallel.  C<threads::tbb> is Free Software;
you may use it and/or modify it under the same terms as Perl itself.

The TBB library itself is GPL-2, with a special exception that you may
use it as a part of a free software library without restriction.
Whether that implies that use of this library imparts the freedoms
granted by the GPL on users receiving copies of software built using
this library, or whether using with, say, a GPL-3 library revokes the
right to copy the software is left as an exercise for the OSS licensing
geek reader.

=cut

