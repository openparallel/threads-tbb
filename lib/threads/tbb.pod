
=head1 NAME

threads::tbb - interface to the Threading Building Blocks (TBB) API

=head1 SYNOPSIS / TODO

 # first instance:
 #   - records %INC
 #   - adds to @INC a closure that keeps a track of loaded modules
 use threads::tbb;

 # a tbb::task_scheduler_init (C++ name) object; list of modules
 # for slave threads will be updated.
 my $sched = threads::tbb::init->new();

 # a chunked sequence generator
 my $range_i = threads::tbb::blocked_int->new(1, 40, 5);

 # a concurrent arrays: deep copy in and out
 tie my @data, "threads::tbb::concurrent::array";

 # do data parallel work
 parallel_for($range_i, \&execute);

 # map/reduce
 my $result = parallel_reduce($range_i, \&execute, \&join);

=head1 DESCRIPTION

This module provides access to a few core TBB API functions to Perl
programs.

The algorithms employed by TBB are quite different to threads as
provided by L<use threads;> - instead of directly starting threads and
managing their communication, an API is provided that provides I<data
paralellism>; in particular, I<divide and conquer> processing with
I<task stealing>.

Instead of writing algorithms from the perspective of a thread and
what the thread should do next, small but substantial (1,000's of Perl
opcode iterations) and non-blocking chunks of work are identified and
kept in thread-affinitive task lists.  Other threads can come along to
and "steal" work from these lists, to keep cores busy.

=head2 Interpreter vs Thread design

When the first C<threads::tbb::init> object is made, one worker
pthread is created for each processor core or virtual core.  This is
performed by the TBB library before the Perl interpreter can C<use
strict;>

Subsequent calls to it will not create new worker pthreads, instead
they will re-use the existing threads.

However these ready-to-go system threads are not Perl interpreter
threads yet and the design needs to be considered;

=over

=item 1. interpreter per pthread

In this mode, as soon as a task gets to run it tries to pick up an
interpreter it has used before.  A C<tbb::concurrent_hash_map> maps
from the thread ID (PID on Linux) to an interpreter; all classes which
implement C<tbb::> algorithms will lock their interpreter in the body
of their C<execute()>, C<join()> bodies etc where user code is run.

=item 1. interpreter at semi-random

As before, except interpreters are kept in a pool and allocated to
threads as they have tasks to run.  This might work or it might not
depending on what assumptions the C<PerlInterpreter> makes about the
thread it is running on.

=item 2. interpreter as a task

The tbb::task is sub-classed, and necessary interpreter
startup/acquisition happens in those areas.

=back

=head2 Module loaded set in slave interpreters

Again there are some ideas here.

=over

=item 1. automatic module use tracking

It is proposed that threads::tbb keeps a record of all of the modules
loaded into the current Perl process.  When modules are loaded, it
keeps track of those modules using an object which lives on @INC.

If you create a C<threads::tbb::init> object with no extra
information, then the slave threads will load all of the same modules
as the current interpreter before they are ready for work.

=item 2. explicit module list

You could also specify the modules directly:

  my $init = threads::tbb::init->new( modules => [ ... ] )

This would by-pass this detection and allow for lower thread start-up
costs.

=back

It should be fast to check that an interpreter is up to date with the
current list of modules, as it will happen on every task wake-up.

=head2 Shared Data

Worker threads do not share any data with the main process.

All functions are passed as serialized closures initially via
C<L<Storable>>.  The serialization preserves closures to
C<threads::tbb::concurrent::> series of thread-safe containers.  All
other closed over variables are cloned and will take independent value
in each worker thread.

C<threads::shared> could also work, but it should only be used for
legacy code as it is Perl's answer to Python's GIL.  This will
probably special support to work.

=back


=head1 CONCEPTS

=head2 Divide and Conquer

The divide and conquer algorithm used by TBB is quite different to
most threading libraries.  Instead of trying to make things like
locking easy, you go for thread-safe operations.

This is a bit like map/reduce.  You can see examples of it in
C<L</parallel_for>> and C<L</parallel_reduce>>, described later.

=head2 Memory model

The blocks which take closures, and the entries in the
C<threads::tbb::concurrent::> containers are all passed via Storable
dumps.

=over

=item 1. objects in interpreter

Objects are copied in and out of a slave interpreter, that never runs
anything (as in C<threads::shared>).  Either as blobs of memory held
by it, or as an assembled data structure.

=item 2. opaque C<Storable> blobs in array

The serialised objects are kept in a C<tbb::concurrent_*> property of
the corresponding C<threads::tbb::concurrent::*> classes.

=back


=head1 FUNCTIONS

Some are too good not to export by default.

=head2 parallel_for

For can be used to process a set of data.  You can use it as a map
function by using a different output array until pipelining primitives
are added.

  use threads::tbb;
  tie my @array, "threads::tbb::concurrent::array";

  @array = @data;  # deep copy

  # get a range for that array.  up to 5 at a time.
  my $array_range = threads::tbb::blocked_int->new(0, $#array, 5);

  # now run parallel_for
  parallel_for( $array_range, sub {
      my $range = shift;

      # code may be executed in a thread.
      # we now have exclusive use of
      #   @array[$range->begin .. $range->end]

      for my $i ($range->begin .. $range->end) {
          my $val = $array[$i];  # another deep copy

          $val->frobnicate();  # change it somehow

          $array[$i] = $val;   # deep copy
      }
  } );

=head2 parallel_reduce

Parallel_reduce is just parallel_for, but with another function to
combine results from the array at the end.  It's not called
parallel_forreduce due to the latter's similarity with an obscure
Pirate Interjection.

  use threads::tbb;
  tie my @array, "threads::tbb::concurrent::array";

  @array = @data;  # deep copy

  # get a range for that array.  up to 5 at a time.
  my $array_range = threads::tbb::blocked_int->new(0, $#array, 5);

  # now run parallel_for
  parallel_reduce( $array_range, sub {
      my $range = shift;

      # code may be executed in a thread.
      # we now have exclusive use of
      #   @array[$range->begin .. $range->end]

      my $price = 0;
      for my $i ($range->begin .. $range->end) {
          my $val = $array[$i];  # another deep copy

          $price += $val->compute_cost();
      }
      return $price;
  },
  sub {
      # fold a value from a and b to a new value.
      # deep copies in and out.  Check b is not undef.
      my ($a, $b) = @_;
      return defined $b ? $a + $b : $a;
  },
  );

=head1 LIES

These goals are for the moment LIES

=head2 LIES/SYNOPSIS

 # if @array is not already a concurrent array, this copies to shared
 # interpreter.  #TODO #LATER
 my $range_a = threads::tbb::blocked_array->new( \@array, 5 );

 # "partitioners" #TODO #LATER that automatically divide domains, eg
 # by "grain size" of work thought to be ~10,000+ cycles of work
 my $part_i = threads::tbb::simple_partitioner->new($range_i, 10);
 # automatic partitioner that keeps dividing arrays and
 # adjusts grain size automatically
 my $part_a = threads::tbb::auto_partitioner->new($range_a);

 my %hash :threads::tbb;
 my @array :threads::tbb;
 my @array :threads::tbb::concurrent_queue;

 # consider: task/group contexts, memory allocation,
 # mutex stuff, timing (tick count)

=head2 parallel_scan #TODO #LATER

... an obscure one; see http://en.wikipedia.org/wiki/Prefix_sum ...

Not implemented.

=head2 parallel_while #TODO

Less obscure

  my $i = 20;
  my $iterator = sub {
      $i-- || undef;
  };
  # deep copied to the sub in this block
  parallel_while($iterator, sub {

      # you can add another iterator to the while block
      parallel_while_add($iterator2);

  });

Each of the iterators added run in the thread context of the
interpreter that added them.

=head2 pipeline / filter

=head2 parallel_sort

=cut

